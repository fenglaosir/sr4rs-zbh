# 超分辨率模型训练步骤

## 一、数据集制作

首先，准备好高分辨率影像和低分辨率影像。
	
先在电脑上使用QGIS进行操作（如果实在不会QGIS可以找周佳灵），导入影像，选择 矢量>研究工具>创建网格（水平间隔和垂直间隔凭感觉来，需要设置的小一点），创建网格完成后，矢量>几何图形工具>质心，创建质心。接下来，矢量>地理处理工具>裁剪，导入一个影像的shp对质点图层进行裁剪。右键裁剪后图层，选择导出>要素另存为，格式选择ESRI形状文件，保存。保存的结果包括（.cpg, .dbf, .prj, .qmd, .shp, .shx）将它们打包成zip，与影像数据一起上传到服务器备用。

接下来，在你的docker环境中创建文件夹，如：/traindata/train1/ 其中traindata 表示保存训练数据，train1表示保存这一次训练使用的数据，以此类推下一次可以是train2之类的，将上述的文件放在这个文件夹里，用 `unzip 文件名` 解压压缩包。（通常无法直接上传到docker环境中，可以先上传到共享文件文件夹，然后用sudo su进入root用户后，cd到docker环境文件夹中，然后使用cp复制到目标文件夹）。

### 示例：
```
sudo su
cd /var/lib/docker/overlay2/8eda2e6c6acd06697ada21db92e33d051aab6f6164fa57c0284c495376da1e47/diff/home/otbuser
//这里是我的docker环境所在的路径，不同的docker环境路径是不同的，区别就在于overlay2和diff中间那一长串，记得很久之前说过找的办法，找到之后最好记下来。
cp /home/zbh/共享文件/test.tif ./traindata/train1/
//注意上面指令中，第二个参数前面的. 表示当前路径
```

进入你的docker环境，需要注意的是，要以root权限进入，格式为`sudo docker exec -u root -it [环境id] bash`

接下来，编写一个脚本来制作数据集。首先创建文件`touch mkdata.sh`，然后`vim mkdata.sh`进入文件编辑器，按电脑上的insert键进入编辑模式，编写如下代码。


```
OTB_TF_NSOURCES=2 otbcli_PatchesExtraction \
-source1.il ./traindata/train1/DiFenbianl_caijianhou_NEW.tif(这里改成你的低分辨率数据路径) \
-source1.patchsizex 32 \
-source1.patchsizey 32 \
-source1.out ./traindata/train1/lr_patches.tif int16 \
-source2.il ./traindata/train1/YJ20240621000009.tif(这里改成你的高分辨率数据路径) \
-source2.patchsizex 128 \
-source2.patchsizey 128 \
-source2.out ./traindata/train1/hr_patches.tif int16 \
-vec ./traindata/train1/patches_center.shp(这里是之前用QGIS生成的shp的路径) \
-field "fid"

```
	
按ESC退出编辑，按`:`键并输入wq，回车保存退出(记得把括号都删掉)。

执行`bash mkdata.sh`

略等一会，若无报错且路径中出现生成的文件，数据集制作完成。

## 二、训练

创建train.sh，编写如下代码。

```
python ./sr4rs/code/train.py \
--lr_patches ./traindata/train1/lr_patches.tif --hr_patches ./traindata/train1/hr_patches.tif \ （这一行是前面生成的两个数据集）
--vggfile ./vgg19.npy \  （这个在共享文件里有，cp过去）
--save_ckpt ./traindata/train1/ckpts/ \ （中断保存点文件夹）
--logdir ./traindata/train1/logs2/ \ （日志文件夹）
--vggweight 0.00003 --l1weight 200 --l2weight 0.0 \
--depth 64 --vggfeatures 1234 --batchsize 4 --adam_lr 0.0002 \
--lr_scale 0.0001 --hr_scale 0.0001 \
--epoch 5 \  （训练时期，正常的训练步骤需要120个，大概要训练半个月以上，跑流程的话设5个）
--savedmodel ./traindata/train1/model （模型保存路径，必须是不存在的路径）

```

执行`nohup bash train.sh > tl.log &`

按Ctrl+C后台运行，`tail -f tl.log`查看输出日志。

## 三、测试
	
老办法，创建test.sh

```
python ./sr4rs/code/sr.py \
--savedmodel ./traindata/train1/model \
--input ./traindata/train1/DiFenbianl_caijianhou_NEW.tif \
--output testmod.tif

```
	
执行`bash test.sh`，看看出来个什么玩意（能出来就是赢）。
